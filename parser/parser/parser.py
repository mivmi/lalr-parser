# Parser LALR(1) Dragon Book. page 269, ...
# The parser is the second stage in the process of a compiler or an interpreter.
# Its primary responsibility is to take the tokens generated by the lexer 
# and transform them into an Abstract Syntax Tree (AST). 
# The AST provides a structured and processable representation 
# for the subsequent stages of the compiler or interpreter.
#
# This parser utilizes the LALR(1) technique, which is an optimized 
# and memory-efficient method for parsing programming language grammars.
# The LALR(1) approach combines similar states (states with the same rules 
# regardless of lookahead tokens) to generate smaller parsing tables.
# This technique reduces memory usage while maintaining the same 
# grammar recognition power and parsing efficiency.
#
# For example, if the grammar (CFG) is as follows:
# E → E + T | T
# T → NUM
#
# The LALR(1) ~ parsing table for this grammar would be:
#
# | State | NUM     | +        | @EOF     | Goto (E) | Goto (T) | Action    |
# |-------|---------|----------|----------|----------|----------|-----------|
# | 0     | Shift 3 | -        | -        | 1        | 2        | -         |
# | 1     | -       | Shift 4  | $Accept  | -        | -        | -         |
# | 2     | -       | Reduce 1 | Reduce 1 | -        | -        | E → T     |
# | 3     | -       | Reduce 2 | Reduce 2 | -        | -        | T → NUM   |
# | 4     | Shift 3 | -        | -        | -        | 5        | -         |
# | 5     | -       | Reduce 3 | Reduce 3 | -        | -        | E → E + T |
#
# https://www.geeksforgeeks.org/lalr-parser-with-examples

import typing as t
from .. import errors, utils

if t.TYPE_CHECKING:
    from ..lexer import BaseLexer

_Rules: t.TypeAlias = t.Dict['NonTerminal', 'Rule']
_ProductCallback: t.TypeAlias = t.Callable[['BaseParser', t.Any], t.Any]

class Symbol:
    def __eq__(self, value):
        if isinstance(value, Symbol):
            value = value.name

        return self.name == value

    def __repr__(self):
        return f'{self.__class__.__name__}({self.name!r})'

    def __hash__(self):
        return hash((self.name, type(self)))

class Terminal(Symbol):
    """
    Terminals are symbols that appear directly in the input stream (Token) and cannot be further expanded.
    They include keywords, operators, identifiers, literals, etc.

    """
    def __init__(self, name: str):
        """
        Create a new `Terminal` instance.

        Args:
            name (str): The name of the symbol (e.g., ID, INT, ...).
        """
        self.name = name

class NonTerminal(Symbol):
    """
    Non-terminals are symbols that can be expanded into other symbols (both terminals and non-terminals).
    They define higher-level constructs in a language's syntax.
    """
    def __init__(self, name: str):
        """
        Create a new `NonTerminal` instance.

        Args:
            name (str): The name of the symbol (e.g., term, factor, ...).
        """
        self.name = name


class Rule:
    """
    Represents a rule in an LALR(1) parser.
    """

    def __init__(self,
                 lhs: 'NonTerminal',
                 follow_set: t.Set['Symbol'] = None,
                 productions: t.List['Production'] = None):
        """
        Create a new `Rule` instance.

        Args:
            lhs (NonTerminal): The left-hand side of the rule (a non-terminal symbol).
            follow_set (Set[Symbol], optional): The follow set for the rule. Defaults to an empty set.
            productions (List[Production], optional): A list of productions associated with the rule. Defaults to an empty list.
        """
        self.lhs = lhs
        self.first_set: t.Set['Symbol'] = set()
        self.follow_set: t.Set['Symbol'] = follow_set or set()
        self.productions: t.List['Production'] = productions or []

    def combine(self, other: 'Rule') -> 'Rule':
        """
        Combines the current rule with another rule.

        Args:
            other (Rule): The other rule to combine with.

        Returns:
            Rule: A new rule with the combined productions of both rules.

        Raises:
            TypeError: If `other` is not an instance of `Rule`.
            ValueError: If the `lhs` of both rules do not match.
        """
        if not isinstance(other, Rule):
            raise TypeError(
                f'Unsupported operand type(s) for +: "Rule" and {type(other).__name__!r}'
            )

        if self.lhs != other.lhs:
            raise ValueError('The left-hand sides (lhs) of both rules are not identical')

        return Rule(self.lhs, None, self.productions + other.productions)

    def __repr__(self) -> str:
        return (
            f'{self.__class__.__name__}('
            f'lhs={self.lhs}, first_set={self.first_set}, '
            f'follow_set={self.follow_set}, productions={self.productions})'
        )

class State:
    def __init__(self, id: int, *rules: 'Rule'):
        """
        Create a new `State` instance.

        Args:
            id (int): A unique identifier for the state.
            *rules (Rule): A variable number of grammar rules associated with this state. 
                These rules define the productions to be processed in this state.
        """
        self.id = id

        self.data: t.Dict[t.Tuple[t.Tuple['NonTerminal', int], int], 'Position'] = {}

        for value in rules:
            self.add_rule(value)

    def __eq__(self, value: 'State') -> bool:
        return self.data == value.data

    def add_rule(self, rule: 'Rule', lookahead: t.Set['Symbol'] = None) -> None:
        """
        Adds each production of the rule as a new position to the state.

        Args:
            rule (Rule): The rule whose productions are to be added.
            lookahead (Set[Symbol], optional): A set of lookahead symbols to be considered 
                for the rule's positions. Defaults to None, meaning no lookahead.
        """
        for index, product in enumerate(rule.productions):
            self.add_position(
                id=(rule.lhs, index),
                lhs=rule.lhs,
                product=product,
                lookahead=lookahead
            )

    def add_position(self,
                     id: t.Tuple['NonTerminal', int],
                     lhs: 'NonTerminal',
                     product: 'Production',
                     position: int = 0,
                     lookahead: t.Set['Terminal'] = None) -> None:
        """
        Adds a position within a production to the state.

        Args:
            id (Tuple[NonTerminal, int]): A unique identifier for the position, consisting of the left-hand side (lhs) 
                of the rule and unique number.
            lhs (NonTerminal): The left-hand side of the rule (non-terminal symbol).
            product (Production): The production associated with this position.
            position (int, optional): The index of the current position within the production's RHS, representing the cursor's position.
                Defaults to 0.
            lookahead (Set[Terminal], optional): A set of terminal symbols representing the lookahead for the current position.
                Defaults to None, meaning no specific lookahead is set.

        If the position already exists in the state, the lookahead set is updated to reflect the new lookahead symbols.
        """
        key = (id, position)
        if key in self.data:
            if lookahead is not None:
                self.data[key].lookahead.update(lookahead)
        else:
            self.data[key] = Position(id, lhs, product, position, lookahead)

    def __repr__(self) -> str:
        return f'State(id={self.id}, data={self.data})'

class Position:
    def __init__(self,
                 id: t.Tuple['NonTerminal', int],
                 lhs: 'NonTerminal',
                 product: 'Production',
                 position: int,
                 lookahead: t.Set['Terminal'] = None):
        """
        Create a new `Position` instance.

        Args:
            id (Tuple[NonTerminal, int]): A unique identifier for the position, consisting of the left-hand side (lhs) 
                of the rule and unique number.
            lhs (NonTerminal): The left-hand side of the production.
            product (Production): The production associated with this position.
            position (int): The current position within the RHS of the production.
            lookahead (Set[Terminal], optional): Set of lookahead symbols for decision-making. 
                Defaults to an empty set if not provided.
        """
        self.id = id
        self.lhs = lhs
        self.product = product
        self.position = position
        self.lookahead = lookahead or set()
        self.visited = False

    def __eq__(self, other):
        if not isinstance(other, Position):
            return False

        return (self.id == other.id
                and self.position == other.position
                and self.lookahead == other.lookahead)

    @property
    def at(self):
        """
        Returns the symbol at the current position in the RHS of the production.

        Returns:
            Symbol: The symbol at the current position.
        """
        return self.product.rhs[self.position]

    @property
    def next(self):
        """
        Returns the next symbol in the RHS of the production.

        Returns:
            Symbol: The next symbol after the current position in the RHS of the production.
        """
        return self.product.rhs[self.position + 1]

    def shift(self, value: int = 1):
        """
        Shifts the position by a given value, moving to the next symbol.

        Args:
            value (int, optional): The number of steps to shift the position. Defaults to 1.

        Returns:
            Tuple: The new Position with the updated position index.
        """
        return self.id, self.lhs, self.product, self.position + value, self.lookahead

    def on_last(self):
        """
        Checks if the position is on the last symbol of the RHS of the production.

        Returns:
            bool: True if the position is at the last symbol in the RHS, False otherwise.
        """
        return self.product.length == self.position + 1

    def is_complete(self):
        """
        Checks if the position has reached the end of the RHS of the production.

        Returns:
            bool: True if the position is complete, meaning it has parsed all symbols 
                  in the RHS. False otherwise.
        """
        return self.product.length == self.position

    def __repr__(self):
        return f'{self.lhs}, len={self.product.length}'
        return (
            'Position('
                f'id={self.id}, '
                f'lhs={self.lhs}, '
                f'product={self.product}, '
                f'position={self.position!r}, '
                f'lookahead={self.lookahead!r}'
            ')'
        )

class Production:
    def __init__(self,
                 lhs: NonTerminal,
                 rhs: t.List[Symbol] = None,
                 hidden: t.Optional[t.Tuple[int]] = None,
                 optional: t.Optional[t.Tuple[int]] = None,
                 callback: t.Optional['_ProductCallback'] = None):

        self.lhs = lhs
        self.rhs = rhs or []
        self.hidden = hidden
        self.optional = optional
        self.callback = callback

    def __call__(self, parser, *args):
        args = list(args)

        # add None args
        if self.optional:
            for index in self.optional:
                args.insert(index - 1, None)

        # remove hidden args
        if self.hidden:
            args = [
                value
                for index, value in enumerate(args, start=1)
                if index not in self.hidden
            ]

        if callable(self.callback):
            return self.callback(parser, *args)

        elif args:
            return args[0] if len(args) == 1 else args

    @property
    def length(self):
        return len(self.rhs)

    def __repr__(self):
        return f'{self.__class__.__name__}(lhs={self.lhs!r}, rhs={self.rhs!r})'

class MetaParser(type):
    """
    Metaclass for dynamically managing rule processing and generating the LALR(1) table.

    This metaclass is responsible for handling the creation of grammar rules, managing the start symbol,
    populating the rules with their corresponding productions, and generating the transition table used 
    by the parser. It also computes the `first` and `follow` sets for grammar rules.
    """

    def __new__(cls, name: str, bases: t.Tuple[type, ...], attrs: t.Dict[str, t.Any]) -> type:
        if bases:
            START = attrs.get('START', 'root')
            if isinstance(START, str):
                START = NonTerminal(START)

            if not isinstance(START, NonTerminal):
                raise ValueError(
                    f'The "START" symbol must be NonTerminal or str, not {type(START).__name__!r}')

            rules = attrs.get('rules', {})
            rules[CONFIRM] = Rule(
                lhs=CONFIRM,
                productions=[
                    Production(CONFIRM, [START, EOF])
                ]
            )

            for key, value in attrs.items():
                if key.startswith('__'):
                    continue

                if isinstance(value, Rule):
                    if value.lhs not in rules:
                        rules[value.lhs] = value
                    else:
                        rules[value.lhs] = value.combine(rules[value.lhs])

                elif isinstance(value, Production):
                    if value.lhs in rules:
                        rules[value.lhs].productions.append(value)
                    else:
                        rules[value.lhs] = Rule(value.lhs, productions=[value])

            attrs['table'] = cls.build_table(rules)

        return super().__new__(cls, name, bases, attrs)

    @classmethod
    def build_table(cls, rules: '_Rules'):
        """
        Builds the LALR(1) transition table by processing the grammar rules.

        This method performs the core logic for parsing the grammar and generating the state transition
        table. It handles the states, shifts, and reduces required for the parsing process, and ensures
        that conflicts (e.g., shift-reduce, reduce-reduce) are detected.

        Args:
            rules (_Rules): The grammar rules to be used for building the table.

        Returns:
            dict: A dictionary representing the LALR(1) transition table.
        """
        result = {}
        merges: t.Dict[int, int] = {}
        states: t.Dict[int, 'State'] = {}
        stacks: t.List[t.List['State']] = [[State(0, rules[CONFIRM])]]

        cls.compute_first_sets(rules)
        cls.compute_follow_sets(rules)

        state_id = 0
        while stacks:
            while stacks[-1]:
                state = stacks[-1].pop()

                finished = False
                while not finished:
                    finished = True
                    lookaheads = []

                    for position in state.data.values():
                        if position.visited or position.is_complete():
                            continue

                        finished = False
                        position.visited = True
                        if isinstance(position.at, NonTerminal):
                            rule = rules[position.at]
                            if position.on_last():
                                lookahead = rule.follow_set
                            else:
                                if isinstance(position.next, Terminal):
                                    lookahead = {position.next}
                                else:
                                    lookahead = rules[position.next].first_set

                            lookaheads.append((rule, lookahead))

                    for rule, value in lookaheads:
                        state.add_rule(rule, lookahead=value)

                # Merge states if identical
                for other in states.values():
                    if state == other:
                        merges[state.id] = other.id
                        break
                else:
                    shift = {}
                    reduce = {}
                    states[state.id] = state
                    merges[state.id] = state.id

                    # Process shift and reduce actions
                    for position in state.data.values():
                        if position.is_complete():
                            for lookahead in position.lookahead:
                                key = (lookahead, state.id)
                                if key in reduce:
                                    raise errors.RRConflictError(f'reduce-reduce conflict: {lookahead}')
                                reduce[key] = position
                        else:
                            key = (position.at, state.id)
                            if key not in shift:
                                state_id += 1
                                shift[key] = State(state_id)

                            shift[key].add_position(*position.shift())

                    for key, value in shift.items():
                        if key in result:
                            raise errors.ConflictError(f'transition already existed: {key}')

                        result[key] = value.id

                    for key, value in reduce.items():
                        if key in shift:
                            raise errors.SRConflictError(f'shift-reduce conflict: {key}')

                        if key in result:
                            raise errors.ConflictError(f'transition already existed: {key}')
                        result[key] = value

                    stacks.append(list(shift.values()))

            stacks.pop()

        cache = {}
        state_ids = set()
        for (position, state_id), value in result.items():
            if isinstance(value, int):
                value = merges[value]
            state_ids.add(merges[state_id])
            cache[(position, merges[state_id])] = value

        state_mapping = {}
        for index, state_id in enumerate(sorted(state_ids)):
            state_mapping[state_id] = index
            if state_id in states:
                states[state_id].id = index

        transition = {}
        for (position, state_id), value in cache.items():
            if isinstance(value, int):
                value = state_mapping.get(value, ACCEPT)
            transition[(position, state_mapping[state_id])] = value

        return transition

    @classmethod
    def compute_first_sets(cls, rules: '_Rules'):
        """
        Computes the `first` set for each rule in the grammar.

        The `first` set represents the possible first symbols that can appear in the expansion of
        a non-terminal. This method iteratively updates the first sets of the rules until they stabilize.

        Args:
            rules (_Rules): The grammar rules to compute the first sets for.
        """
        finished = False
        while not finished:
            finished = True
            for rule in rules.values():
                for product in rule.productions:
                    if product.length == 0:
                        continue

                    first = product.rhs[0]
                    value = (
                        {first}
                        if isinstance(first, Terminal)
                        else rules[first].first_set
                    )

                    if not rule.first_set.issuperset(value):
                        finished = False
                        rule.first_set.update(value)

    @classmethod
    def compute_follow_sets(cls, rules: '_Rules'):
        """
        Computes the `follow` set for each rule in the grammar.

        The `follow` set represents the symbols that can appear immediately after a non-terminal.
        This method iteratively updates the follow sets of the rules until they stabilize.

        Args:
            rules (_Rules): The grammar rules to compute the follow sets for.
        """
        finished = False
        while not finished:
            finished = True
            for rule in rules.values():
                for product in rule.productions:
                    if product.length == 0:
                        continue

                    last = product.rhs[-1]
                    if isinstance(last, NonTerminal):
                        if not rules[last].follow_set.issuperset(rule.follow_set):
                            finished = False
                            rules[last].follow_set.update(rule.follow_set)

                    for index, current in enumerate(product.rhs[1:]):
                        previous = product.rhs[index]
                        if isinstance(previous, NonTerminal):
                            value = (
                                {current}
                                if isinstance(current, Terminal) else
                                rules[current].first_set
                            )
                            if not rules[previous].follow_set.issuperset(value):
                                finished = False
                                rules[previous].follow_set.update(value)

class BaseParser(metaclass=MetaParser):
    """
    The `BaseParser` class is responsible for converting tokens
    into an abstract syntax tree (`AST`) based on the defined rules.
    This class uses a metaclass (`MetaParser`)
    for dynamically managing rule processing and generating the `LALR(1)` table.
    It serves as a foundation for creating custom parsers, enabling developers to extend and define production rules.

    # How to Define Rule/Production
    * A rule is defined using the `Rule` class, and productions are defined using the `Production` class.
    You can define a rule by assigning a `Rule` instance to an attribute.

    Example 1:
    ```python

    class MyParser(BaseParser):
        add = Rule(
            NonTerminal('E'),
            productions=[
                Production(
                    NonTerminal('E'),
                    rhs=[NonTerminal('E'), Terminal('+'), NonTerminal('T')]
                )
            ]
        )
    ```

    * A Production defines how a non-terminal is expanded.
    You can also define a production directly like this:
    ```python
    t_as_e = Production(NonTerminal('E'), rhs=[NonTerminal('T')])
    ```

    # Defining a Set of Rule's:
    * To define a set of grammar rule's, you can use a `rules` attribute, which is a dictionary where the
    key is a `NonTerminal` symbol and the value is the corresponding `Rule`.

    Example 3:
    ```python
    class MyParser(BaseParser):
        rules = {
            NonTerminal('E'): Rule(...)
        }
    ```

    * to customize the output tree, you can use a `callback` for a production or use the `grammar` decorator.

    Example 4:
    ```python
    class MyParser(BaseParser):
        @grammar('E `+`! T', name='E') 
        def add(self, left: Token, right: Token):
            return {'_': 'add', 'left': left.value, 'right': right.value}
    ```
    Attributes:
        LEXER (BaseLexer):
            A lexer class responsible for tokenizing input strings based on defined rules.
        START (Union[str, NonTerminal]):
            The starting point of the grammar, defined as a NonTerminal symbol.

    """

    LEXER: t.Type['BaseLexer']
    START: t.Union[str, 'NonTerminal']
    rules: t.Dict['NonTerminal', 'Rule'] 
    table: t.Dict[t.Tuple['Symbol', int], t.Union[int, 'Position']]

    def parse(self, content: str, name: str = '<stdin>'):
        """
        Parses the given input string using the lexer and the parser's lalr table.

        Args:
            content (str): The content to be parsed.
            name (str, optional): The name of the input content. Defaults to '<stdin>'.

        Example:
            ```python
            parser = MathParser()
            ast = parser.parse('10 + 2 * (25 - 10)')
            print(ast)
            ```
        """

        lexer = self.LEXER(content, name=name)

        stack = []
        states = [0]

        last_token = None
        error_token = token = lexer.get_next_token()

        while True:
            try:
                state = states[-1]
                action = self.table.get(
                    (Terminal(token.name), state)
                )

                if action is None:
                    error_token = (
                        token 
                        if token.name != '$EOF' 
                        else last_token or token
                    )

                    if (
                        error_token.value is None
                        or '\n' in repr(error_token.value)
                    ):
                        title = 'token'
                        token_value = error_token.name

                    else:
                        title = error_token.name.lower()
                        token_value = error_token.value

                    raise SyntaxError(f'Unexpected (state_id: {state}) {title} {token_value!r}')

                elif action == ACCEPT:
                    return stack[0] if stack else None

                elif isinstance(action, int): # shift
                    stack.append(token)
                    states.append(action)

                    last_token = token
                    token = lexer.get_next_token()

                elif isinstance(action, Position): # Reduce
                    args = stack[-action.product.length:]
                    stack = stack[:-action.product.length]
                    states = states[:-action.product.length]
                    states.append(self.table[(action.lhs, states[-1])])

                    if last_token is not None:
                        error_token = last_token

                    response = action.product(self, *args)
                    if response is not None:
                        stack.append(response)

            except SyntaxError as error:
                if not isinstance(error, (errors.LexerError,
                                          errors.ParseError)):

                    if content:
                        lineno, column, line = utils.get_position_info(
                            content,
                            position=error_token.position[0] + 1
                        )
                        error = errors.ParseError(
                            error.msg,
                            (name, lineno, column, line)
                        )
                    else:
                        error = errors.ParseError(error.msg)

                raise error from error

EOF = Terminal('$EOF')
ACCEPT = Terminal('@ACCEPT')
CONFIRM = NonTerminal('@CONFIRM')
